# -*- coding: utf-8 -*-
"""python_deep.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jyXER19mggeur8jFUWoX18aIjHLw83SJ

## ***Solar power prediction using Deep learning***

# Import necessary libraries
"""

import pandas as pd
import numpy as np
import tensorflow as tf
from keras.layers import Dense, Activation, BatchNormalization, Dropout
from keras import regularizers
from keras.optimizers import RMSprop, Adam, SGD
import datetime
import matplotlib.pyplot as plt
import seaborn as sns

"""# Import dataset"""

dts = pd.read_csv('spg.csv')
dts.head(10)

import pandas as pd

class FileLoader:
    def __init__(self, file_path):
        self.file_path = file_path
        self.data = None

    def load_file(self):
        raise NotImplementedError("Subclasses should implement this method")

    def display_head(self, n=10):
        if self.data is not None:
            print(self.data.head(n))
        else:
            print("Dataset not loaded. Please load the dataset first.")

class CsvLoader(FileLoader):
    def load_file(self):
        self.data = pd.read_csv(self.file_path)
        print(f"Dataset loaded successfully from {self.file_path}")

# Creating an instance of the CsvLoader class with the file path 'spg.csv'
loader = CsvLoader('spg.csv')

# Loading the dataset
loader.load_file()

# Displaying the first 10 rows
loader.display_head()

"""# Feature selection"""

#features which impact target
dts.corr()["generated_power_kw"].sort_values(ascending=False)

df1 = pd.DataFrame(df)
X = df1[["temperature_2_m_above_gnd","mean_sea_level_pressure_MSL","shortwave_radiation_backwards_sfc","snowfall_amount_sfc","azimuth","wind_direction_80_m_above_gnd","wind_direction_10_m_above_gnd"]]
y = dts.iloc[:, -1].values #last column is assigned as target
print(X.shape, y.shape)
y = np.reshape(y, (-1,1))  # reshaping target to one column
y.shape

X

y

"""# **Splitting train and test datasets**"""

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)
print("Train Shape: {} {} \nTest Shape: {} {}".format(X_train.shape, y_train.shape, X_test.shape, y_test.shape))

"""#**Feature scaling**"""

from sklearn.preprocessing import StandardScaler
# input scaling
sc_X = StandardScaler()
X_train = sc_X.fit_transform(X_train)
X_test = sc_X.transform(X_test)

# outcome scaling:
sc_y = StandardScaler()
y_train = sc_y.fit_transform(y_train)
y_test = sc_y.transform(y_test)

X_train

X_test

y_train

"""#**Neural Network**"""

import tensorflow as tf

class SPFNetBuilder:
    def __init__(self, n_layers, n_activation, kernels, input_dim):
        self.n_layers = n_layers
        self.n_activation = n_activation
        self.kernels = kernels
        self.input_dim = input_dim
        self.model = None

    def build_model(self):
        self.model = tf.keras.models.Sequential()
        for i, nodes in enumerate(self.n_layers):
            if i == 0:
                self.model.add(tf.keras.layers.Dense(nodes, kernel_initializer=self.kernels,
                                                      activation=self.n_activation, input_dim=self.input_dim))
            else:
                self.model.add(tf.keras.layers.Dense(nodes, activation=self.n_activation, kernel_initializer=self.kernels))
        self.model.add(tf.keras.layers.Dense(1))  # single layer in output
        self.model.compile(loss='mse', optimizer='adam', metrics=[tf.keras.metrics.RootMeanSquaredError()])

    def summary(self):
        if self.model is not None:
            self.model.summary()
        else:
            print("Model not built yet. Please call build_model() first.")

# Usage:
n_layers = [32, 64]
n_activation = 'relu'
kernels = 'normal'
input_dim = X_train.shape[1]  # assuming X_train is available
spf_net_builder = SPFNetBuilder(n_layers, n_activation, kernels, input_dim)
spf_net_builder.build_model()
spf_net_builder.summary()

hist = spfnet.fit(X_train, y_train, batch_size=32, validation_data=(X_test, y_test),epochs=30, verbose=2)

spfnet.evaluate(X_train, y_train)

train_pred = spfnet.predict(X_train) # get model predictions (scaled inputs here)
train_pred_orig = sc_y.inverse_transform(train_pred) # unscale the predictions
y_train_orig = sc_y.inverse_transform(y_train) # unscale the true train outcomes

from sklearn.metrics import r2_score

rf_results = pd.DataFrame(['ANN', r2_score(train_pred_orig, y_train_orig), r2_score(k, y_test_orig)]).transpose()
rf_results.columns = ['Method', 'R2 Score of Training Set', 'R2 Score of Test Set']
rf_results

plt.plot(hist.history['root_mean_squared_error'])
#plt.plot(hist.history['val_root_mean_squared_error'])
plt.title('Root Mean Squares Error')
plt.xlabel('Epochs')
plt.ylabel('error')
plt.show()

y_pred = spfnet.predict(X_test)
y_pred_orig = sc_y.inverse_transform(y_pred) # unscale the predictions
y_test_orig = sc_y.inverse_transform(y_test)

results = np.concatenate((y_test_orig, y_pred_orig), 1)
results = pd.DataFrame(data=results)
results.columns = ['Real Solar Power Produced', 'Predicted Solar Power']
#results = results.sort_values(by=['Real Solar Power Produced'])
pd.options.display.float_format = "{:,.2f}".format
#results[800:820]
results[7:18]

import matplotlib.pyplot as plt

# Extracting the data for the specified range
selected_results = results.iloc[7:18]

# Plotting the graph
plt.figure(figsize=(10, 6))
plt.plot(selected_results.index, selected_results['Real Solar Power Produced'], label='Real Solar Power Produced', marker='o')
plt.plot(selected_results.index, selected_results['Predicted Solar Power'], label='Predicted Solar Power', marker='x')
plt.xlabel('Data Point')
plt.ylabel('Solar Power (kW)')
plt.title('Real vs Predicted Solar Power')
plt.legend()
plt.grid(True)
plt.show()

corr = dts.corr()
plt.figure(figsize=(22,22))
sns.heatmap(corr, annot=True, square=True);